
## 推荐系统基本思路
GMV, Gross Merchandise Volume, 是网站成交金额
gmv= 销售额 + 取消订单金额 + 拒收订单金额 + 退货订单金额

不同推荐场景中，低阶组合特征或高阶组合特征 可能都会对最终CTR预估产生影响。
高阶特征，用DNN，
点击率预测，是一个二分类问题。


因子分解机FM，通过对每一维特征的隐变量内积来提取特征。由于计算复杂度原因，一般只用到二阶。

简单来看FM = LR + 低阶特征的两两组合。FM将二阶参数维度从n2 降低到nk。
SVM引入核函数来学习交叉特征，为两两的特征组合分配一个权重参数。核函数为二阶多项式核的SVM模型。这会有特征维度的灾难。

FFM(field-aware factorizaiton machines)不仅特征和特征之间有关系，特征和特征类型有关系。


在实践中DeepFM可能效果还没有Wide&Deep好。


DeepFM工程化过程中，遇到了特征稀疏、一列多值、共享权重的情况。
借石塔西的实现。其局限性：其底层用的tensorflow框架里的高阶api，灵活性低一些。另外无法保存auc最优的模型，early stopping也不能保证停留在效果最好的阶段。线上预测阶段是不能按照文件的方式去读取。

对以上问题进行工程化改造，上线运行。效果点击率PV提升2.67%，点击率UV提升3.64%，平均点击数提升4.53%。

推荐系统实际工程需要注意样本、特征、算法方方面面的问题。

推荐模式
由于app推荐的物品通常是十几分钟到几小时的长视频课程学习，且课程数量相对较少，学员存在断续观看、重复观看的需求；并且几百门课如果采用feed流方式（推荐视频不重复）很容易就把所有课程内容刷没了。因此没有使用feed流的推荐模式，而是使用了topN推荐。

算法架构
由于推荐的物品课程总量仅为百级，因此没有做召回而实现了排序+重排序。为了解决有限的计算资源与实效性之间的矛盾，采用了实时异步的架构，即在用户有行为时去为用户预测一个新的课程列表并缓存，在用户请求时，才将这个缓存列表发给用户，即拉模式（pull），整体架构如下：


如何选择正负样本？样本冲突了怎么办？如何使得样本表达的内容丰富，受到噪声干扰比较小？在线系统的特征获取比离线训练某些特征数据有延迟怎么办？
面对以上问题，整个样本的生成采取宁缺毋滥的原则，对于不确定是否正确的数据，均不采纳。例如简单的样本时间错误（数据生成时间早于动作时间或数据生成时间与动作时间相差太远等），这种数据剔除掉。下面重点讲正负样本的选择、样本冲突、样本下采样和数据穿透问题。


1）正负样本的选择
2）样本冲突
3）样本下采样
4）数据穿透


1）正负样本的选择
2）样本冲突
3）样本下采样
4）数据穿透




##  推荐系统公平性
用户侧
生产侧




## 推荐系统实时性


## 推荐系统去重
去重拆解两个子问题
相同物料去重(物料ID相同，物料ID不同)
近似物料重复推荐, 如我已经看过美股暴跌的新闻璐璐，为何刷新后又推荐了一篇相似的。

去重问题是最基础的用户体验，推荐系统精简到极致，可以只有两个功能
1）热度排行榜，让每个用户都有物料可以看
2）去重：让每个用户看到新的内容

如何解决
后端去重 vs 客户端去重。

物料ID相同的去重
推荐系统可以看成一个漏斗，所有候选集经过后端召回、排序、重排、客户端才展示给用户。所以去重越靠近召回层越好。最理想的去重是在召回服务的索引中去重， 其次在召回结果中去重，最差在排序后去重，客户端为后端去重失败做兜底。

物料ID不同的去重
以视频为例，物料A和B内容上是相同的，但是不同人上传的。主要的思路是给每个物料一个哈希值，哈希值作为物料ID进行去重，上面所探讨的去重方法就可以适用了。具体实现上，把文本映射到哈希值已经很成熟了，搜索引擎在索引网页时就需要去重，但把视频映射成哈希值还有很多挑战，例如加水印、加黑边、裁剪、改变分辨率、截取部分视频，都有可能让算法误以为两个视频是不同的

近似物料重复推荐
用户问题：我已经看过“美股暴跌”的新闻了，为什么刷新后又推荐了一篇，他们都在说一件事，只是来自不同的媒体。
困难点：近似的界限难以确定。相关性和重复性是有模糊的交集的。
解决思路

1）利用用户的负反馈，如用户的跳过/不感兴趣反馈。
在召回和排序两个层面解决
召回可以考虑在 U2I 召回里，在User侧加入负反馈embeding，作为对比，I2I召回很难处理负反馈。
排序，除了可以把负反馈物料用作ID特征，还可以考虑构建<user, item>的实时特征。

2）多样性手段。




意义
去重问题，站在用户的角度来说，就是“感觉推荐结果重复”一句话；但站在技术角度，解决问题需要把问题拆解成客户端、后端、NLP/CV标注等不同的任务，很锻炼端到端解决问题的能力，又是推荐系统的核心用户体验。


## 推荐系统多样性
用户视角多样性：我的推荐结果全都是体育相关的，如果能推荐些二次元主题的会更好
内容生态视角多样性：抛开单个用户，整个系统是不是能够把流量分配给不同主题的创作者
两者关系：用户多样性好不意味着内容生态多样性好，例如，用户A和B的推荐结果有体育和二次元，但视频都是最流行的那几个，流量偏向头部，内容生态多样性不足。


用户视角多样性
为什么会有多样性不足
技术原因
召回阶段：如果采用双塔结构 (user embedding x item embedding)，user embedding只有一个，跟user embedding相近的item embedding也就很难具有多样性 （有很多工作在模型层面解决这个问题）
排序阶段：1) 排序是point-wise的，打分只依赖于当前候选集的特征，已经有k个体育类的内容得到了高分，不影响第k+1个体育内容得到高分；2) 召回的候选集本身就缺乏多样性，无论排序怎么做，出来的结果都不够多样
产品原因： 新产品上线，原来没有二次元内容，现在引入，模型给二次元的打分都很低，因为缺乏历史数据
为了解决召回和排序过后的多样性不足，需要重排序，也就有了推荐系统三大件：召回 + 排序 + 重排序




## 推荐系统冷启动问题



## auc较好，但ctr不佳的问题


## 推荐系统多目标训练
ctr点击率预测、收入预测

排序模型，它训练数据和优化目标是展示  不同用户对不同广告的点击率。
这与同一个用户面对不同广告的点击率预测还是有一个gap。这部分问题如何比较好的解决？
1）召回- 排序- 重排的框架，让重排框架来解决
2）learn to rank中有 pointwise, pairwise, listwise.
这三者中pairwise比pointwise好。
listwise肯定是性能最好的。



为何需要多目标
1）推荐系统中的显示反馈较少，因为大多数用户反馈都不是直接评分。
隐式反馈如用户点击、收藏、分享、观看时长、购买等
在评估用户满意度的时候会存在一些认知偏差，包括目标偏差、物品偏差、用户偏差。

目标偏差：目标不同，偏好程度不同。
比如电商场景中，购买这个行为表达的偏好高于收藏；
比如视频的场景中，观看时长超过20s这个行为表达的偏好高于点击。

物品偏差：被推荐物品需要多个衡量目标，单个目标衡量不全面。
短视频推荐，如果仅以视频播放完成率为目标，就可能在视频中留下悬念，需要观看下一个，让用户多操作，用户会不满意；
比如信息流推荐，如果仅以点击率为目标，就可能被标题党钻了空子；如果仅以转发分享为目标，就可能存在转发保平安之类的内容。

用户偏差：不同用户表达满意的方式不同。
比如知乎上观看文章，有的用户喜欢点赞，有的用户喜欢收藏。

通过一些方法来解决目标偏差、物品偏差和用户偏差的问题，完成多目标的优化。

比如说，电商场景，希望能够在优化GMV（付款+未付款）的基础上提高点击率；

信息流场景，希望在提高用户点击率的基础上提高用户关注，点赞，评论等行为。

因此推荐系统做到后期，往往会向多目标学习演化，承担起更多的业务目标，以提高用户的粘性。


多目标排序问题的解决方案
大致有四种(好多选择了方案4 )
1）改变样本权重
2）多模型分数融合
3）排序学习learning to rank(LTR)
4）多任务学习multi-task learning(MTL)

1）改变样本权重
点击和分享都是正样本
通过这种方法能够在优化某个目标（点击率）的基础上，优化其他目标（分享率）。在实际AB测试的过程中会发现，通过调整样本权重的这样的方法，原始目标A会受到一定的损失以换取新增加目标B的增长，实现初级的多目标优化。

优点:模型简单，通过梯度乘以样本权重设计目标函数，不需要额外架构支持，没有增加算法时间复杂度。

2）多模型分数融合
比较常用的方法。

召回- 排序- 重排，
重排阶段，根据排序传递过来的 CTR， CVR，stay， cart， collect等分数进行融合。
缺点：
线上服务需要有额外的时间开销，需要将多个模型预测的结果组合。
不同目标难以量化评估重要性。
样本部分特征稀疏，模型准确率低。
模型融合的超参难以学习。

那么如何更好地确定超参呢？
实际应用中，通过AB测试不断尝试，以线下和线上的评价指标提高为目标,找到一组合适的超参。本质上还是多个目标函数的加权。

3）排序学习learning to rank(LTR)
举一个pair-wise以视频推荐为例子，用户观看很长时间的i视频，点击了j视频,那么我们觉得观看比点击重要。用户u在视频i和视频j之间的偏好和其他的视频无关。

优点：
优化了目标排序，不需要设计复杂的超参数，能取得比排序好的效果。
本身就是单个模型有多个目标，线下好训练，线上服务压力小。

缺点：
有些相对顺序不好构造，训练样本中没有的关系，在预测时可能存在。
样本数量增大，训练速度变慢，需要构造的情况多。
样本的不平衡性会被放大。举例：有的用户有十次点击，有的只有一次，在构造的时候十次的会构造更多的样本，一次的就吃亏。

4）多任务学习multi-task learning(MTL)
在多任务学习算法之前，一般采用简单的样本加权、多模型分数融合方法、直接用排序学习的算法来实现多目标排序。现在常用多任务学习来实现多目标排序。
多任务学习也算迁移学习的一个分支。

团“猜你喜欢”深度学习排序模型是将点击率和下单率拆分，网络在最后一个全连接层进行拆分，单独学习对应 Loss 的参数。
线上预测时，将Click-output和Pay-output做一个线性融合。


参数的软共享机制，每个任务都有自己的参数和模型结构，可以选择哪些共享哪些不共享。最后通过正则化的方式，来拉进模型参数之间的距离，例如使用 L2 进行正则化。在线上服务的时候，花费的时间要比硬参数共享机制化的多，因为模型结构更加复杂了。


可以选择共享全部特征参数，
也可以选择只共享bottom参数。

模型有阿里的ESMM等。



为何多模型学习是有效的？
多任务学习有效的原因是引入了归纳偏置（inductive bias），有两个效果:

1）互相促进：可以把多任务模型之间的关系看作是互相先验知识，也称归纳迁移（inductive transfer），有了对模型的先验假设，可以更好的提升模型的效果；解决数据稀疏性其实本身也是迁移学习的一个特性，在多任务学习中也同样会体现。
2）泛化作用：不同的模型学到的表征不同，可能A模型学到的是B模型所没有学好的，B模型也有其自身的优点，而这一点很可能是A学不好的一方面。这样一来模型的健壮就更加的强了，具体很好的泛化能力。


## 正负样本采样
ctr预测场景下， 排序模型中
1）用户点击 - 正样本
2）曝光用户未点击  - 负样本

3）未曝光，不能确定是正样本还是负样本

召回模型中，
1）用户点击 - 正样本（数量太少了）
2）大数据里随机抽样，但非相关话题的样本 -  负样本（保证各个话题有）

重排模型，




## 推荐系统实践
fm - deepfm22017 -  xdeepfm

deepfm实践










