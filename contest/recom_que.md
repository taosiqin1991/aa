
### 职业规划
3年，职业发展第一道门槛。

要不要转型/换赛道的苦恼。

人生如戏，全靠随机。

我作为少数几个从事互联网并生存下来的代表，狠狠吐槽目前互联网的产品生态，对黄赌毒广告颇为不满，虽然黄赌毒让我收入相当不错，但是对这个行业的内卷，道德谴责下的厌恶，职业发展和应届生无法区分也持续困扰着我，十分想找新的赛道发展，特别是涉足传统行业的数字化转型领域。他坦诚我们这些念物理出来的唯一好处，就是有着更加难得可贵的精神，就是被世道摧残无数轮，仍然保持长远的眼光，坚决不会和短视妥协。他揶揄我躺平只是躺，没有站，希望我尽早站起来。

他现在顶级基金公司数据专家，他分析过非常多的创投公司，和大公司董秘交涉较多，提到他们要推动一个行业更新，是首先游说证监会，然后让证监会对头部上市公司施压，让头部上司公司引领行业转型，实现一些新的创业机会，并不是我幼稚地以为多几个科技从业者，或者解决卡脖子问题就能改变现状。

我痛苦根源，是我没从更高的角度去思考和接受这种职业，码农从来只是负责解决公司问题，而不是面向解决行业问题，因此也谈不上积累行业的解决方案。所以你发现出去面试，经验可能不是特别有用，总是要你和应届生一起面试刷题读论文，也是因为互联网并不是一个行业，而是一种加速资本流动的载体。

让我别去考虑大公司 2B 的可能。他清楚目前一些互联网喊着 2B，宏观上，甚至很多公司都没这耐心以及能力去改变细分行业的标准，特别是耐心，只是受制于资本压力，零碎地解决边边角角的需求。比如光是统一中国几个大海关的商品类目标准，就不指望互联网去搞，只能靠传统行业的头部公司推动。你会看到现状是，行业各种不标准是阻碍数据转型一大杀手，尤其是增加了交流的成本，打个比方，你不清楚衣服的生产上游需要的原材料是啥，某种工艺需要耗时多少，这些都是圈内的门道，总是要派一个懂行的过去对接（由行会来负责），其实这个懂行的人，充当的角色是做标准化的转换接口，如果只是一单一单来搞，人应付地过来，不需要机器。但是订单量高，件急，各种款式各种布料就能让人直接犯难，这也是阿里出来灵犀的一个目的。但是阿里能不能成，很大程度是要看阿里长期处于浙江，深刻知道服饰领域细节，知道如何和传统行业打交道才有这个基础。年轻的互联网公司，比如头条要入局教育，他坚决不看好，因为张一鸣并没有长期在某个细分领域打拼的经历，头条教育内部肯定混乱无比，因为只有打法，没有标准，是根本不足以领导一个公司入局一个传统领域的。

他批评码农过于狂妄自大，看不起这看不起那，他说有些互联网公司员工这么狂，他觉得公司还是太年轻没明白世道，中美对抗，在国家顶层的眼里已经是名声败坏的了，不像西方，中国政党是超越三界之外的存在，不会成为资本和宗教的奴隶，如果有必要，有的是备选方案让某个行业霸主迅速更新换代，而下手点，就是靠金融资本。


### 广告中专业名词
PV访问量，page view，具体是指网站的是页面浏览量或者点击量，页面被刷新一次就计算一次。如果网站被刷新了1000次，那么流量统计工具显示的PV就是1000。

UV独立访客，unique visitor，访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次。

VV(VisitView)：访客的访问次数，用以记录所有访客1天内访问了多少次您的网站。当访客完成所有浏览并最终关掉该网站的所有页面时便完成了一次访问，同一访客1天内可能有多次访问行为，访问次数累计；

P(独立IP数)：指1天内使用不同IP地址的用户访问网站的数量，同一IP无论访问了几个页面，独立IP数均为1

CPC ：Cost Per Click ，每次点击费用，即点击单价。
CPM ：Cost Per Mile 千次展示费用，即广告展示一千次需要支付的费用。
RPM ：RevenuePerMille  千次展示收入，和CPM 类似，RPM 是针对广告展示商（比如Adsense 商户）而言的。

CTR ：Click-throughRate ，点击率，点击次数占展示次数的百分比。


### 推荐系统哪些坑

https://www.zhihu.com/search?type=content&q=cpc


https://zhuanlan.zhihu.com/p/188228577




学习率不宜过小，mini_batch_size不宜过大

广告预估ctr最高的结果不一定会被用户看到
新闻推荐系统中，推荐引擎会对召回的新闻（大概是300篇候选集）给个ctr预估值，然后将这些新闻按照ctr从高到低排序，ctr值排在最前面的新闻一般都会进入用户的手机屏幕被用户刷到。但是在广告推荐系统中，ctr预估结果高的被用户看到的概率明显比新闻推荐系统低，因为广告系统是个三方博弈的过程，也就是广告主、平台、用户之间的一个平衡，广告主希望自己的广告有更多的曝光机会并且出价还低，平台希望选出ctr和ecpm都高的广告，这样广告主满意，自己挣的钱也多，用户至少是不希望出现自己讨厌的广告，有多大兴趣点击就不一定了。这样对比就知道，往往广告平台推荐系统给出的ctr很高、离线和实时的auc很高，但是收入可能没怎么增长，所以广告的ctr优化比新闻推荐系统ctr优化要更难。

喜欢新闻的人不一定对类似的广告也感兴趣
这个比较好理解，经常刷新闻看某个频道的人不一定就对类似的广告感兴趣。刚开始的时候我们把用户看新闻得到的用户画像直接用在广告ctr预估模型里面，通过计算模型特征的sensitivity，结果发现很多用户新闻特征对广告ctr预估模型的贡献并不大。所以在广告算法里面，做look like很重要，也就是通过一类人找到另一类相似的人，比如通过分析一批种子用户的财富水平得到其他所有用户的财富水平，这对于贷款类、珠宝类广告主就非常有用，因为一般穷人更愿意贷款，有钱人才消费的起珠宝。


cvr模型预估的数据延迟上报问题
广告推荐系统里面有很多不同类型的广告，比如cpc、cpm、cpi、cps等等。除了需要预估ctr模型，我们通常还会预估cvr模型，cvr模型可以简单理解为点击到安装的预估，主要是cpi类型的广告，这类广告通常需要给出一个install/click的预估值。然后问题就来了，很多时候用户click信息上报的比较快，但是install信息由于存在广告收入归因的问题，往往可能在一天甚至几天后才收到这个数据，这对我们模型训练有很大的干扰，因为线上的cvr预估往往都是近实时的，如果一个正例来的很晚，模型准确率自然就低。

ctr
cpc
cpi
cps
cvr




我来补充几个：

i2i/simirank等相似计算算法中的哈利波特问题，相似性计算在推荐系统的召回起到非常重要的作用，而热门物品和用户天然有优势。因此，处理方法基本上都是凭经验，会出现各种magic number的参数。

svd/svd++等算法，在各种比赛中大放异彩，但是据我所知，各大互联网公司中基本没有用它的。

i2i及它的各种变种真是太好用了，大部分公司的业务量，从ROI来看，其实没有必要再做什么优化了。

推荐的召回策略多优于少，但系统的计算rt是个问题，没有好的系统架构，也没有什么优化空间。

i2i等类似计算算法，实际业务中容易跑挂，比如用spark就容易oom，很容易发生倾斜，处理起来又有很多trick和dirty job。

推荐系统不只有召回，召回后的ranking起到非常大的作用，这个和广告的点击率预估有点像。

非常多的业务没有办法向头条/facebook之类的有稳定的用户留存指标，而留存是推荐系统非常重要目标，因此需要找各种折中的指标去知道abtest。


训练样本穿越/泄露问题，即在训练的特征中包含了测试集的样本的信息，这个是初期非常容易犯的错误，在后期有时也会隐秘的发生。大部分推荐系统的训练数据需要在离线条件下去拼接，其中用户的行为状态和时间有关，拼接非常容易出问题，因为系统当时的状态会有各种状况（延时、数据不一致）等，导致训练和实际在线的数据不一致，建议把训练需要的日志在实际请求中直接拼接好打印落盘。

最后，算法的作用有点像前辈们讲的：短期被人高估，长期被人低估。按目前国内业务方对算法有了解的特别少，算法对生态的长短期影响，只能靠算法负责人去判断，因此，就算你只是个打工的，请有一颗做老板的心。




推荐系统评估的实体是什么
商品、新闻、服务还是广告


推荐系统的优化方向是什么
要么优化点击率、要么优化转化成交率、或者每次浏览的成交金额。

当然淘宝的主搜索排序是用很多优化目标的模型essemble的结果，这也是没办法，因为非常重要， 单独为某项目标优化不科学不正确。


推荐系统的优化指标是什么
有了优化方向以后，需要一些组合指标来组成一个真正的优化指标如 NDCG
评估一个完整的商品序列的质量。当然除非在大体量数据的公司，否则很难有多数据做 NDCG，更可能的还是单点 CTR预估。


特征工程
如果用机器学习的思路来求解此问题，在给定许多样本的前提下，给出一个用户，要预测一个商品排序的指标。需要去找特征。

用户的静态行为，动态行为
商品的特征(包括商品图片特征、图片上是否有文字，占多大面积， 图片上有无人像，背景什么颜色)
上下文特征(用户来这个页面之前看/买了什么商品，在什么特别的页面呆过，比如用户中心，购物车，用户当前访问的设备是什么，空间时间坐标是什么等)

按传统机器学习方法你对这些特征去做转换、切分、叠加、离散化、组合。有时还会用比较弱的模型输出来作特征。


模型训练
推荐系统，商品几亿级别，用户几亿级别，计算量大。可以先选分布式的近似线性时间的算法，如LR。
再用 GBDT, FM, DeepFM, Wide&Deep等。
考虑多模型结构。


实际遇到的坑
1）假定已训练一个很完美模型，有100万的商品池子，要对这100万商品都算一遍指标然后排序吗？浪费计算力。

可以先用召回策略，给每个用户先匹配几千几百的商品。（简单粗暴的模型如 CF等）
或者先把100万商品过滤一下，精选出10万比较靠谱的商品(好像少见)

2) 用户总看到一样的商品，会烦躁，效果不佳。
实际输出到推荐系统前端的商品，都是远远多于展现位置的。比如算出来一个用户此时最喜欢的商品会是item1,,, item100, 每次展现通过策略和规则每次看到的是 item1, it6, it11,,,

3) 不合规商品的召回，如暴力/色情及其他。
可以有平台视频内容安全算法岗，来召回。
或者其他策略、规则把这些不合规内容过滤掉。


4) 用户刚买过某商品(如一个月前买过macbookpro)，再推荐没有意义。
真正工业环境下的模型。不可能捕捉所有的上下文信息和用户商品特征，所以有点蠢。
需要加入很多人工规则干预。这是一个典型案例。
   
5)  一个商品我买完了，哪有那么快重复消费呀，满屏都是我不需要的东欧关系，很难再看到随便逛让人眼前一亮的商品。至少要判定顾客是不是已消费、重复消费同类商品，社会平均需要多久再推荐。

对于这个问题，判断两个商品是不是同一个商品，平台也是有困难的。对于macbookpro，京东自营为主，sku也就10+。
但淘宝就非常困难了，很多人在卖不同的macbookpro。比较困难。
 
   


做好推荐
推荐系统是一个强业务问题。需要了解老板的目标，了解用户的目标，最后才是模型的目标。

1）刚入坑时，把深度学习引入推荐，wide&deep，deepfm甚至cnn用的不亦悦乎，数据上也提升不少。可是老板直接来个截图，这东东非常让人反感，我有这么low嘛。数据只是kpi 的一部分。就像今日头条一样，你算法推的再好，你的模型没有社会主义价值观，不能增加正能量，全部归零。

2）某天，更新模型后，发现数据大幅度增加，开心之余，rtx腾讯通 却响个不停：外网用户反馈一直推足球相关信息。一检查，忘记考虑用户兴趣多样性了，只推用户最喜欢的东西也会反感。

3）某天，像往常一样，数据继续上涨，大老板来反馈，怎么总给我推荐这些经典的东西，那谁谁谁新出了专辑，不能推给我吗
很多用户喜欢新鲜的事物。

4）某天，收到告警，数据大幅度下降，我大吃一惊，难道线上出问题了吗？仔细排查，原来刚发了新版本app，业务入口变了。。
做推荐，一个小小的ui 改动，影响就比模型大得多。

5）有一次，尝试 lstm做召回模型，吭哧吭哧做了半个月，上限灰度，发现数据下降了。。被老板挑战没有输出。
到了某个程度，很难提高数据了。kpi怎么办呢。



一次高大上的模型落地失败总结
https://zhuanlan.zhihu.com/p/48656958



某地沟油外卖想用强化学习提升用户浏览时长，结果模型把用户经常吃的店铺直接放到最底，搞得用户每次都拼命滑屏才找到自己想吃的，变相提高浏览时长

某黄赌毒 app 想给搜索框里面的候选 query 做强化学习排序，提高下拉推荐 query 的点击，结果发现用户昨天点过的 query 一直放到第一位，原因是产品隐藏了很多用户历史感兴趣的链接，导致用户被迫使用搜索寻找自己之前感兴趣的链接，然而用户懒的输入，都是希望靠搜索背下自己曾经写下的 query

某黄赌毒 app 想靠强化学习，在内容流上强插广告，希望提高广告收入，同时不降低整体内容点击，结果发现 cpm/cpc 广告特喜欢插到第 4 个位置，原因是前面几条，政策上必须要是时事政治，用户从来不看，都是一滑就过，拇指滑屏，大概率就是滑过 3 条，然后用户开始浏览花边新闻，娱乐八卦，只要第 5 条是黄色擦边的内容，用户大概率驻足观看，强行让第 4 条曝光，系统最优解基本是第 4 条广告，第 5 条黄赌毒

某买假货的 app 想靠强化学习打通链路，提高用户复购率，结果当然是满屏都推送打折促销厕纸洗衣液避孕套等生活不得不经常买的东西



### 推荐系统工程师
problem - data - model - algorithm - metrics - problem 
上述链条的闭环。





### 常见问题
1） 指标上不去，rank 加特征能够提升吗？

分析办法：把 rank 分数分成若干区间，每个区间统计真实的 ctr，更近一步，可以拆分成多个桶，比如按照某个特征拆分成 A，B 两组，单独统计每组的真实 ctr



2）PV 增大，但是 CTR 跌的很厉害
数学上，PV 增加 CTR 就会跌，但一般都会是常数，如果 PV 增加 CTR 跌太厉害，你就需要警惕你的投放人群了。


3）如何寻找快速提升指标的策略
有一些野路子可以提供，说其是野路子，着实是没法有通用的解法，每个人都有自己的一套特殊的秘方。其次，生产线大部分策略都是被动产生，比如修各种 bad case ，或者紧急针对某个单一业务指标做提升，或者产品拍了脑袋找你改进样式啥的。主动寻找增量策略本身是一个比较老中医的方案。

一种做法是复制上下文环境：这种技巧需要花钱买教训收集一定的反馈。打个比方，你要提升用户点击视频的概率，前期你并不知道那些用户爱看视频，所以在不同时间点，人群和位置上，随机试投了一阵，收益当然不佳。然后你认为这些随机当中，还是有一些样本误打误撞到最佳的策略上的，于是你把用户分成 A，B 两组，A 组用户特爱点视频（你认为他们爱点，是因为恰好蒙对了策略环境），B 组用户不怎么点。

复制上下文环境就是说，给 B 人群营造 A 人群的环境。数学上来说，就是统计一下 A 组的环境 s 都是啥（比如说视频都在啥位置，一次性投放视频的数目，视频热度等），然后想办法把这些上下文迁移到 B 组人群身上。


第二种是增强关联：这种技巧抽象来说，就是溯源，找到影响某个指标，最有可能的特征 A，然后强化该指标和该特征的关系，需要和 rank 配合着打。


4）如何统计曝光次数少的 item 的热度
一般来说，很多 item 的曝光次数可能只有数十次，高热度的 item 曝光可能是上万，甚至百万次，曝光过低的 item，只要产生少数几次点击，其 ctr 就有可能非常高，甚至吊打高热 item 的点击率，统计学上针对这种问题，一般是采取 wilson ctr 做纠正，但是现实来说，wilson ctr 非常不靠谱，曝光低的 item，大概率是你精准投放人群导致的，并不满足 wilson ctr 随机投放的基本假设。确切来说，我们要分人群去统计相对的 ctr，消除投放人群的 bias。

方法：假设 item A 被投放给 N 个人，曝光 200 次，产生 10 次点击，同时，这 N 个人当中，高热 item B 给他们曝光了 100000 次，产生 900 次点击。所以，A 和 B 在同一批人群当中的 ctr 分别是：（10 / 200， 900 / 100000），一般我们认为高热的 item 都是无关个性化的，比如热点新闻，促销商品，黄色暴力内容，大家都爱点，高热 item 的点击率和投放人群的关系不是很大，几乎人人都会点，可以作为 CTR 本底。扣除这种 ctr 表示，相比大众货，用户更喜欢点那些 item，用这种相对的 ctr 作为 item 热度的衡量。




第一次，穷人心态，开了几百 batch-size，效果好差，分布式开了几万 batch-size 终于有好一点的结果。

召回，10亿 乘 亿级召回，不算难问题，这个要离线快速更新：
开始就选择 spark + faiss ， spark 做分桶，faiss 桶内召回。由于不做服务， faiss 没必要用特殊的 index。结果系统太老，faiss 挂不到 spark 上，懒得和系统部扯皮。换成分布式跑 faiss，自己切片数据分桶，慢的一比。
由于系统老，tensorflow 1.10 挂 spark 都不好配环境，也只能绕路挂集群跑完拖hdfs 上，二的不得了。。
我把这个命名为：准实时更新系统。。我挫，咬我呀



### 点击广告的人的心态，转化的人的心态










